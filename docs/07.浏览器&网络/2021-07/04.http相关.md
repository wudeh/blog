---
title: http 1.x, 2.x, 3.0
sidebar: auto
date: 2021-07-09 00:00:00
tags: 
  - 网络
categories: 
  - 网络
permalink: /pages/9764240c8551b/
---

## HTTP

超文本传输协议，「HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范」。

## 0.9

1991 年,原型版本，功能简陋，只有一个命令 GET,只支持纯文本内容，该版本已过时。

## 1.0

- 任何格式的内容都可以发送，这使得互联网不仅可以传输文字，还能传输图像、视频、二进制等文件。
- 除了 GET 命令，还引入了 POST 命令和 HEAD 命令。
- http 请求和回应的格式改变，除了数据部分，每次通信都必须包括头信息（HTTP header），用来描述一些元数据。
- 只使用 header 中的 If-Modified-Since 和 Expires 作为缓存失效的标准。
- 不支持断点续传，也就是说，每次都会传送全部的页面和数据。通常每台计算机只能绑定一个 IP，所以请求消息中的 URL 并没有传递主机名（hostname）

## 1.1

目前最为主流的 http 协议版本，从 1999 年发布至今，仍是主流的 http 协议版本。

- 引入了持久连接（ persistent connection），即 TCP 连接默认不关闭，可以被多个请求复用，不用声明 Connection: keep-alive。长连接的连接时长可以通过请求头中的 keep-alive 来设置。
- 引入了管道机制（ pipelining），即在同一个 TCP 连接里，客户端可以同时发送多个
  请求，进一步改进了 HTTP 协议的效率。
- HTTP 1.1 中新增加了 E-tag，If-Unmodified-Since, If-Match, If-None-Match 等缓存控制标头来控制缓存失效。支持断点续传，通过使用请求头中的 Range 来实现。
- 使用了虚拟网络，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个 IP 地址。
- 新增方法：PUT、 PATCH、 OPTIONS、 DELETE。

## 1.x 版本问题

- 数据明文：在传输数据过程中，所有内容都是明文，客户端和服务器端都无法验证对方的身份，无法保证数据的安全性。
- 队头阻塞：HTTP/1.1 版本默认允许复用 TCP 连接，但是在同一个 TCP 连接里，所有数据通信是按次序进行的，服务器通常在处理完一个回应后，才会继续去处理下一个，这样子就会造成队头阻塞。
- http/1.x 版本支持 Keep-alive，用此方案来弥补创建多次连接产生的延迟，但是同样会给服务器带来压力，并且的话，对于单文件被不断请求的服务，Keep-alive 会极大影响性能，因为它在文件被请求之后还保持了不必要的连接很长时间。

### 解决 HTTP 队头阻塞的方法

- 并发连接：对于一个域名而言，是允许分配多个长连接的，那么可以理解成增加了任务队列，也就是说不会导致一个任务阻塞了该任务队列的其他任务，在 RFC 规范中规定客户端最多并发 2 个连接，不过实际情况就是要比这个还要多，举个例子，Chrome 中是 6 个。
- 域名分片：可以在一个域名下分出多个二级域名出来，而它们最终指向的还是同一个服务器，这样子的话就可以并发处理的任务队列更多，也更好的解决了队头阻塞的问题。
  举个例子，比如 aaa.com，可以分出很多二级域名，比如 Day1.aaa.com，Day2.aaa.com,Day3.aaa.com,这样子就可以有效解决队头阻塞问题。

## 2.0

### 头部压缩

- `头部压缩`：HTTP 1.1 版本会出现 「User-Agent、Cookie、Accept、Server、Range」 等字段可能会占用几百甚至几千字节，而 Body 却经常只有几十字节，所以导致头部偏重。HTTP 2.0 使用 `HPACK` 算法进行压缩。`HPACK` 算法原理：
- `索引表`：对头部信息建立索引表，每个索引对应一个值，比如索引为 2 对应头部中的 method 头部信息，这样子的话，在传输的时候，不在是传输对应的头部信息了，而是传递索引，对于之前出现过的头部信息，只需要把「索引」(比如 1，2，...)传给对方即可，对方拿到索引查表就行了。这种「传索引」的方式，可以说让请求头字段得到极大程度的精简和复用。
- `哈夫曼编码`：对于整数和字符串进行「哈夫曼编码」，哈夫曼编码的原理就是先将所有出现的字符建立一张索引表，然后让出现次数多的字符对应的索引尽可能短，传输的时候也是传输这样的「索引序列」，可以达到非常高的压缩率。

### 多路复用

HTTP 1.x 中，如果想并发多个请求，必须使用多个 TCP 链接，且浏览器为了控制资源，还会对单个域名有 6-8 个的 TCP 链接请求限制。
HTTP2 中：

> 同域名下所有通信都在单个连接上完成。单个连接可以承载任意数量的双向数据流。数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装，也就是 Stream ID，流标识符，有了它，接收方就能从乱序的二进制帧中选择 ID 相同的帧，按照顺序组装成请求/响应报文。

注意：HTTP2.0 协议的多路复用机制解决了 HTTP 层的队头阻塞问题，但是在 TCP 层仍然存在队头阻塞问题。

### 服务器推送

浏览器发送一个请求，服务器主动向浏览器推送与这个请求相关的资源，这样浏览器就不用发起后续请求。

相比较 http/1.1 的优势 👇

- 推送资源可以由不同页面共享
- 服务器可以按照优先级推送资源
- 客户端可以缓存推送的资源
- 客户端可以拒收推送过来的资源

### 二进制分帧

- 之前是明文传输，不方便计算机解析，对于回车换行符来说到底是内容还是分隔符，都需要内部状态机去识别，这样子效率低，HTTP/2 采用二进制格式，全部传输 01 串，便于机器解码。
- 这样子一个报文格式就被拆分为一个个二进制帧，用「Headers 帧」存放头部字段，「Data 帧」存放请求体数据。这样子的话，就是一堆乱序的二进制帧，它们不存在先后关系，因此不需要排队等待，解决了 HTTP 队头阻塞问题。
- 在客户端与服务器之间，双方都可以互相发送二进制帧，这样子「双向传输的序列」，称为流，所以 HTTP/2 中以流来表示一个 TCP 连接上进行多个数据帧的通信，这就是多路复用概念。

流传输的特性:

- 并发性。一个 HTTP/2 连接上可以同时发多个帧，这一点和 HTTP/1 不同。这也是实现多路复用的基础。
- 自增性。流 ID 是不可重用的，而是会按顺序递增，达到上限之后又新开 TCP 连接从头开始。
- 双向性。客户端和服务端都可以创建流，互不干扰，双方都可以作为发送方或者接收方。
- 可设置优先级。可以设置数据帧的优先级，让服务端先处理重要资源，优化用户体验。

那乱序的二进制帧，是如何组装成正确的报文呢？

- 所谓的乱序，值的是不同 ID 的 Stream 是乱序的，对于同一个 Stream ID 的帧是按顺序传输的。
- 接收方收到二进制帧后，将相同的 Stream ID 组装成完整的请求报文和响应报文。
- 二进制帧中有一些字段，控制着优先级和流量控制等功能，这样子的话，就可以设置数据帧的优先级，让服务器处理重要资源，优化用户体验。

### HTTP2.0 之后以前不必要的优化

取消合并资源

- 在 HTTP/1.1 中要把多个小资源合并成一个大资源，从而减少请求。而在 HTTP/2 就不需要了，因为 HTTP/2 所有的请求都可以在一个 TCP 连接发送。

取消域名拆分

- 取消域名拆分的理由同上，再多的 HTTP 请求都可以在一个 TCP 连接上发送，所以不需要采取多个域名来突破浏览器 TCP 连接数限制这一规则了。

## HTTPS

HTTPS = HTTP + SSL/TLS

基于现在 TLS 主流版本是 1.2，所以接下来梳理的是「TLS/1.2 握手过程」。

### 对称加密

加密和解密用同一个秘钥的加密方式叫做对称加密。Client 客户端和 Server 端共用一套密钥

### 非对称加密

采用的算法是 RSA，所以在一些文章中也会看见「传统 RSA 握手」，基于现在 TLS 主流版本是 1.2，所以接下来梳理的是「TLS/1.2 握手过程」。

非对称加密中，我们需要明确的点是 👇

- 有一对秘钥，「公钥」和「私钥」。
- 公钥加密的内容，只有私钥可以解开，私钥加密的内容，所有的公钥都可以解开，这里说的「公钥都可以解开，指的是一对秘钥」。
- 公钥可以发送给所有的客户端，私钥只保存在服务器端。

### 数字签名

- 将网站的信息，通过特定的算法加密后形成数字签名
- 数字签名在客户端和服务端都会生成，两个数字签名的比对结果将决定浏览器是否信任数字证书

### 数字证书

- 服务端生成数字签名后，用第三方机构的私钥对数字签名进行加密，再加上非对称算法的公钥，就是数字证书
- 数字证书 = 非对称加密的公钥 + 三方机构加密后的数字签名

### SSL 连接断开后如何恢复？

有两种方法来恢复断开的 SSL 连接，一种是使用 session ID，一种是 session ticket。

- 使用 session ID 的方式，每一次的会话都有一个编号，当对话中断后，下一次重新连接时，只要客户端给出这个编号，服务器如果有这个编号的记录，那么双方就可以继续使用以前的秘钥，而不用重新生成一把。目前所有的浏览器都支持这一种方法。但是这种方法有一个缺点是，session ID 只能够存在一台服务器上，如果我们的请求通过负载平衡被转移到了其他的服务器上，那么就无法恢复对话。

- 另一种方式是 session ticket 的方式，session ticket 是服务器在上一次对话中发送给客户的，这个 ticket 是加密的，只有服务器能够解密，里面包含了本次会话的信息，比如对话秘钥和加密方法等。这样不管我们的请求是否转移到其他的服务器上，当服务器将 ticket 解密以后，就能够获取上次对话的信息，就不用重新生成对话秘钥了。


### HTTPS 加密流程

- 1.浏览器发起一个 HTTPS 请求，连接 443 端口。这个过程可以理解成是「请求公钥的过程」。给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法。
- 2.服务端收到请求后，将证书中部分数据信息用 Hash 算法生成消息摘要，通过第三方机构私钥加密消息摘要，生成数字签名，会把数字证书（非对称公钥 + 数字签名 + 发布机构`CA` + 证书有效期 等等）发送给浏览器。以及一个服务器生成的随机数
- 3.浏览器查找操作系统中的证书发布机构 `CA`，和服务器发来的证书中的颁发者 `CA` 作比对，校验证书是否为合法机构颁发；如果为合法证书，浏览器通过第三方机构的公钥对数字签名进行解密，得到消息摘要；浏览器通过 `Hash` 算法根据证书内容信息生成消息摘要，两个消息摘要进行比对，比对成功则信任该数字证书，得到非对称加密算法的公钥；
- 4.生成一个新的随机数（Premaster secret），并使用数字证书中的非对称公钥，加密这个随机数，发给服务端，同时根据三个随机数生成对称密钥，发送给服务端
- 5.服务端使用非对称加密的私钥，解密获取客户端发来的随机数（即Premaster secret），同时根据三个随机数生成对称密钥。服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供客户端校验。
- 接下来，就可以通过该对称密钥对传输的信息加密/解密啦

## HTTP 3.0

HTTP3.0 又称为 HTTP Over QUIC，其弃用 TCP 协议，改为使用基于 UDP 协议的 QUIC 协议来实现。

- HTTP3.0 既然选择了 QUIC 协议，也就意味着 HTTP3.0 基本继承了 HTTP2.0 的强大功能，并且进一步解决了 HTTP2.0 存在的一些问题，同时必然引入了新的问题。

### 队头阻塞问题

- 队头阻塞 Head-of-line blocking(缩写为 HOL blocking)是计算机网络中是一种性能受限的现象，通俗来说就是：一个数据包影响了一堆数据包，它不来大家都走不了。

- 队头阻塞问题可能存在于 HTTP 层和 TCP 层，在 HTTP1.x 时两个层次都存在该问题。

- HTTP2.0 协议的多路复用机制解决了 HTTP 层的队头阻塞问题，但是在 TCP 层仍然存在队头阻塞问题。

- TCP 协议在收到数据包之后，这部分数据可能是乱序到达的，但是 TCP 必须将所有数据收集排序整合后给上层使用，如果其中某个包丢失了，就必须等待重传，从而出现某个丢包数据阻塞整个连接的数据使用。

- QUIC 协议是基于 UDP 协议实现的，在一条链接上可以有多个流，流与流之间是互不影响的，当一个流出现丢包影响范围非常小，从而解决队头阻塞问题。

### 连接迁移

网络切换几乎无时无刻不在发生。

TCP 协议使用五元组来表示一条唯一的连接，当我们从 4G 环境切换到 wifi 环境时，手机的 IP 地址就会发生变化，这时必须创建新的 TCP 连接才能继续传输数据。

QUIC 协议基于 UDP 实现摒弃了五元组的概念，使用 64 位的随机数作为连接的 ID，并使用该 ID 表示连接。

基于 QUIC 协议之下，我们在日常 wifi 和 4G 切换时，或者不同基站之间切换都不会重连，从而提高业务层的体验。

### 丢包重传

HTTP/2 主要的问题在于，多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。

- HTTP/2 多请求复用一个 TCP 连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。

这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！UDP 发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的一个丢包全部重传问题。

UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。

- QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响。
- TL3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack。
- HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 TLS/1.3 的三次握手。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。

## 短轮询、长轮询和 WebSocket 
短轮询的基本思路:

- 浏览器每隔一段时间向浏览器发送 http 请求，服务器端在收到请求后，不论是否有数据更新，都直接进行
响应。这种方式实现的即时通信，本质上还是浏览器发送请求，服务器接受请求的一个过程，通过让客户端不断的进行请求，使得客户端能够模拟实时地收到服务器端的数据的变化。

优缺点👇

- 优点是比较简单，易于理解。
- 缺点是这种方式由于需要不断的建立 http 连接，严重浪费了服务器端和客户端的资源。当用户增加时，服务器端的压力就会变大，这是很不合理的。

长轮询
长轮询的基本思路:

- 首先由客户端向服务器发起请求，当服务器收到客户端发来的请求后，服务器端不会直接进行响应，而是先将
这个请求挂起，然后判断服务器端数据是否有更新。
- 如果有更新，则进行响应，如果一直没有数据，则到达一定的时间限制才返回。客户端 JavaScript 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接。

优缺点👇

- 长轮询和短轮询比起来，它的优点是「明显减少了很多不必要的 http 请求次数」，相比之下节约了资源。
- 长轮询的缺点在于，连接挂起也会导致资源的浪费。

WebSocket

- WebSocket 是 Html5 定义的一个新协议，与传统的 http 协议不同，该协议允许由服务器主动的向客户端推送信息。使用 WebSocket 协议的缺点是在服务器端的配置比较复杂。
- WebSocket 是一个全双工的协议，也就是通信双方是平等的，可以相互发送消息。

## 正向代理和反向代理

### 正向代理
我们常说的代理也就是指正向代理，正向代理的过程，它隐藏了真实的请求客户端，服务端不知道真实的客户端是谁，客户端请求的服务都被代理服务器代替来请求。

### 反向代理
这种代理模式下，它隐藏了真实的服务端，当我们向一个网站发起请求的时候，背后可能有成千上万台服务器为我们服务，具体是哪一台，我们不清楚，我们只需要知道反向代理服务器是谁就行，而且反向代理服务器会帮我们把请求转发到真实的服务器那里去，一般而言反向代理服务器一般用来实现负载平衡。

## 负载平衡的两种实现方式

- 一种是使用反向代理的方式，用户的请求都发送到反向代理服务上，然后由反向代理服务器来转发请求到真实的服务器上，以此来实现集群的负载平衡。

- 另一种是 DNS 的方式，DNS 可以用于在冗余的服务器上实现负载平衡。因为现在一般的大型网站使用多台服务器提供服务，因此一个域名可能会对应多个服务器地址。当用户向网站域名请求的时候，DNS 服务器返回这个域名所对应的服务器 IP 地址的集合，但在每个回答中，会循环这些 IP 地址的顺序，用户一般会选择排在前面的地址发送请求。以此将用户的请求均衡的分配到各个不同的服务器上，这样来实现负载均衡。这种方式有一个缺点就是，由于 DNS 服务器中存在缓存，所以有可能一个服务器出现故障后，域名解析仍然返回的是那个 IP 地址，就会造成访问的问题。




